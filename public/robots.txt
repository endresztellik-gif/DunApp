# robots.txt for DunApp PWA
# This file controls search engine crawler access

# Allow all robots
User-agent: *
Allow: /

# Disallow sensitive paths (security)
Disallow: /.well-known/
Disallow: /api/
Disallow: /*.json$

# Sitemap
Sitemap: https://dunapp.netlify.app/sitemap.xml

# Crawl delay to prevent DoS (1 second between requests)
Crawl-delay: 1

# Security note: This file does not provide security,
# but it helps prevent accidental exposure of sensitive endpoints.
# Real security is enforced via authentication and authorization.
